{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project\n",
    "\n",
    "import os\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import re\n",
    "import geopandas as gpd\n",
    "from math import ceil\n",
    "from urllib.parse import unquote\n",
    "import glob\n",
    "from sqlalchemy import text\n",
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "dataset_directory = \"/Users/shaoziheng/Desktop/4501/project/datasets\"\n",
    "TAXI_ZONES_DIR = \"/Users/shaoziheng/Desktop/4501/project/datasets/taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"/Users/shaoziheng/Desktop/4501/project/datasets/weather\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    \"\"\"\n",
    "    Load and preprocess a shapefile containing taxi zone data.\n",
    "\n",
    "    Args:\n",
    "        shapefile (str): Path to the shapefile containing taxi zone boundaries. \n",
    "                         The shapefile must include `LocationID` or similar \n",
    "                         geographic attributes.\n",
    "                        \n",
    "    Returns:\n",
    "        A GeoDataFrame with added `longitude` and \n",
    "        `latitude` columns corresponding to the centroids\n",
    "        of the taxi zones.\n",
    "    \"\"\"\n",
    "    g = gpd.read_file(shapefile)\n",
    "    g = g.to_crs(4326)\n",
    "    g['longitude'] = g.centroid.x\n",
    "    g['latitude'] = g.centroid.y\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Web scraping links for downloading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch URL from the TLC page\n",
    "def get_all_urls_from_tlc_page(taxi_page):\n",
    "    \"\"\"\n",
    "    Fetch the HTML content from the provided TLC page URL and parse it with BeautifulSoup.\n",
    "\n",
    "    Args:\n",
    "        taxi_page (str): The URL of the TLC webpage containing the data links.\n",
    "\n",
    "    Returns:\n",
    "        BeautifulSoup: A parsed BeautifulSoup object containing the HTML content \n",
    "                       of the webpage for further processing.\n",
    "    \"\"\"\n",
    "    response = requests.get(taxi_page)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch page content: {response.status_code}\")\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract URLs for yellow taxi and HVFHV data from the TLC page\n",
    "\n",
    "def filter_parquet_urls(soup):\n",
    "    \"\"\"\n",
    "    Extract URLs for yellow taxi and HVFHV trip data in Parquet format from the TLC webpage.\n",
    "\n",
    "    Args:\n",
    "        soup (BeautifulSoup): A BeautifulSoup object containing the parsed HTML of the TLC webpage.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - yellow_taxi_links (list): List of URLs for yellow taxi Parquet files.\n",
    "            - hvfhv_links (list): List of URLs for HVFHV Parquet files.\n",
    "\n",
    "    Description:\n",
    "        - Identifies links that match the naming pattern for yellow taxi and HVFHV trip data.\n",
    "        - Decodes encoded characters (e.g., `%20` -> space) in the URLs.\n",
    "        - Filters links based on file naming conventions for years 2020-2024.\n",
    "    \"\"\"\n",
    "    yellow_taxi_links = []\n",
    "    yellow_links = soup.find_all('a', {'href': re.compile(r\"yellow_tripdata_202[0-3]-\\d{2}\\.parquet|yellow_tripdata_2024-(0[1-8])\\.parquet\")})\n",
    "    for link in yellow_links:\n",
    "        url = link['href'].strip()  # Remove leading/trailing spaces\n",
    "        url = unquote(url)  # Decode any encoded characters like %20\n",
    "        yellow_taxi_links.append(url)\n",
    "        \n",
    "    hvfhv_links = []\n",
    "    hvfhv_links_soup = soup.find_all('a', {'href': re.compile(r\"fhvhv_tripdata_202[0-3]-\\d{2}\\.parquet|fhvhv_tripdata_2024-(0[1-8])\\.parquet\")})\n",
    "    for link in hvfhv_links_soup:\n",
    "        url = link['href'].strip()  # Remove leading/trailing spaces\n",
    "        url = unquote(url)  # Decode any encoded characters like %20\n",
    "        hvfhv_links.append(url)\n",
    "        \n",
    "    return yellow_taxi_links, hvfhv_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9779b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download  the Yellow Taxi & High-Volume For-Hire Vehicle (HVFHV) trip data parquet files and save them to directory\n",
    "\n",
    "def download_parquet_file(urls, output_directory):\n",
    "    \"\"\"\n",
    "    Downloads Parquet files from a list of URLs and saves them to the specified directory.\n",
    "\n",
    "    Args:\n",
    "        urls (list): List of URLs to download.\n",
    "        output_directory (str): Path to the directory where files will be saved.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If a file fails to download.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    for url in urls:\n",
    "        file_name = os.path.basename(url)\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "\n",
    "        try:\n",
    "            print(f\"Downloading {url}...\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()  # Raise an error for failed requests\n",
    "\n",
    "            # Write the file content to disk\n",
    "            with open(output_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:  # Filter out keep-alive chunks\n",
    "                        file.write(chunk)\n",
    "\n",
    "            print(f\"Saved to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc350086",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=get_all_urls_from_tlc_page(TLC_URL)\n",
    "yellow_taxi_links, hvfhv_links = filter_parquet_urls(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "030a4830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2024-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2023-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2022-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-10.parquet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2021-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2020-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/yellow_tripdata/yellow_tripdata_2020-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2024-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2023-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2023-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-08.parquet...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2022-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2022-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2021-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2021-12.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-01.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-01.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-02.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-02.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-03.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-03.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-04.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-04.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-05.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-05.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-06.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-06.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-07.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-07.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-08.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-08.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-09.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-09.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-10.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-10.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-11.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-11.parquet\n",
      "Downloading https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2020-12.parquet...\n",
      "Saved to /Users/shaoziheng/Desktop/4501/project/datasets/fhvhv_tripdata/fhvhv_tripdata_2020-12.parquet\n"
     ]
    }
   ],
   "source": [
    "# Download Yellow Taxi files\n",
    "download_parquet_file(yellow_taxi_links, os.path.join(dataset_directory, \"yellow_tripdata\"))\n",
    "\n",
    "# Download Uber HVFHV files\n",
    "download_parquet_file(hvfhv_links, os.path.join(dataset_directory, \"fhvhv_tripdata\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c0ea4b",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4ddcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sample size using Cochran's formula with 95% CI and 5% marginal error.\n",
    "\n",
    "def calculate_sample_size(population, confidence_level=0.95, margin_of_error=0.05):\n",
    "    \"\"\"\n",
    "    Calculate the sample size using Cochran's formula, considering finite population correction.\n",
    "\n",
    "    Args:\n",
    "        population (int): Total population size for which the sample size needs to be calculated.\n",
    "        confidence_level (float): Desired confidence level (default is 0.95 for 95% CI).\n",
    "        margin_of_error (float): Allowable margin of error (default is 0.05 for 5%).\n",
    "\n",
    "    Returns:\n",
    "        int: The calculated sample size, rounded up to the nearest integer.\n",
    "\n",
    "    Formula:\n",
    "        Cochran's formula for infinite population:\n",
    "            n0 = (Z^2 * p * (1 - p)) / e^2\n",
    "        Where:\n",
    "            - Z: Z-score corresponding to the confidence level.\n",
    "            - p: Estimated proportion of the population (default: 0.5 for maximum variability).\n",
    "            - e: Margin of error.\n",
    "\n",
    "        Finite population correction for population size N:\n",
    "            n = n0 / (1 + (n0 - 1) / N)\n",
    "    \"\"\"\n",
    "    Z = {0.9: 1.645, 0.95: 1.96, 0.99: 2.576}[confidence_level]\n",
    "    p = 0.5\n",
    "    e = margin_of_error\n",
    "    sample_size = (Z**2 * p * (1 - p)) / e**2\n",
    "    if population < 1e6:  # Finite population correction\n",
    "        sample_size = sample_size / (1 + (sample_size - 1) / population)\n",
    "    return ceil(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b2d57c",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b71420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cleaning_and_combine_taxi(input_directory, output_file):\n",
    "    \"\"\"\n",
    "    Apply the `clean_taxi_month` function to all Parquet files in the input directory\n",
    "    and combine the cleaned and sampled files into a single large Parquet file.\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): Path to the directory containing the Parquet files.\n",
    "        output_file (str): Path to save the combined cleaned Parquet file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Get all Parquet files in the directory\n",
    "    parquet_files = glob.glob(f\"{input_directory}/*.parquet\")\n",
    "    \n",
    "    all_cleaned_data = []  # To store all cleaned DataFrames\n",
    "\n",
    "    # Apply cleaning to each file\n",
    "    for file_path in parquet_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # load taxi zone data\n",
    "        taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "        taxi_zones = taxi_zones[['LocationID', 'longitude', 'latitude', 'zone', 'borough']]\n",
    "        df = pd.read_parquet(file_path)\n",
    "        lat_map = dict(zip(taxi_zones['LocationID'], taxi_zones['latitude']))\n",
    "        lon_map = dict(zip(taxi_zones['LocationID'], taxi_zones['longitude']))\n",
    "        \n",
    "        # Apply the transformations from clean_taxi_month\n",
    "        df['pickup_latitude'] = df['PULocationID'].map(lat_map)\n",
    "        df['pickup_longitude'] = df['PULocationID'].map(lon_map)\n",
    "        df['dropoff_latitude'] = df['DOLocationID'].map(lat_map)\n",
    "        df['dropoff_longitude'] = df['DOLocationID'].map(lon_map)\n",
    "\n",
    "        # remove invalid location IDs - drop rows where any of the values are missing \n",
    "        df = df.dropna(subset=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "        \n",
    "        # Filter out invalid data points (non-positive fare, tip, passenger, trip distance)\n",
    "        df = df[(df['fare_amount'] > 0) & (df['tip_amount'] >= 0) & \n",
    "                (df['total_amount'] >= 0) & (df['passenger_count'] > 0) & \n",
    "                (df['trip_distance'] > 0)]\n",
    "        \n",
    "\n",
    "        # remove rows where pickup and dropoff latitudes/longitudes are the same or very close\n",
    "        df = df[(df['pickup_latitude'] != df['dropoff_latitude']) & \n",
    "                (df['pickup_longitude'] != df['dropoff_longitude']) & \n",
    "                (abs(df['pickup_longitude'] - df['dropoff_longitude']) > 0.001)]\n",
    "        \n",
    "        # Normalize column names\n",
    "        df.columns = [col.lower().strip().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "        # Remove trips that start and/or end outside of the NEW_YORK_BOX\n",
    "        NEW_YORK_BOX_COORDS = [(40.560445, -74.242330), (40.908524, -73.717047)]\n",
    "        df = df[(df['pickup_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & \n",
    "                (df['pickup_latitude'] <= NEW_YORK_BOX_COORDS[1][0]) & \n",
    "                (df['pickup_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & \n",
    "                (df['pickup_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "        df = df[(df['dropoff_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & \n",
    "                (df['dropoff_latitude'] <= NEW_YORK_BOX_COORDS[1][0]) & \n",
    "                (df['dropoff_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & \n",
    "                (df['dropoff_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "        \n",
    "        # remove unnecessary columns \n",
    "        df = df[['tpep_pickup_datetime','tpep_dropoff_datetime','fare_amount','tip_amount', 'extra', 'improvement_surcharge',\n",
    "                  'congestion_surcharge', 'airport_fee', 'mta_tax', 'tolls_amount', 'pickup_latitude','pickup_longitude',\n",
    "                 'dropoff_latitude','dropoff_longitude', 'trip_distance'\n",
    "                ]]\n",
    "        \n",
    "        # Convert data types after filtering\n",
    "        df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'], errors='coerce')\n",
    "        df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'], errors='coerce')\n",
    "        df['fare_amount'] = df['fare_amount'].astype(float, errors='ignore')\n",
    "        df['tip_amount'] = df['tip_amount'].astype(float, errors='ignore')\n",
    "        df['extra'] = df['extra'].astype(float, errors='ignore')\n",
    "        df['improvement_surcharge'] = df['improvement_surcharge'].astype(float, errors='ignore')\n",
    "        df['congestion_surcharge'] = df['congestion_surcharge'].astype(float, errors='ignore')\n",
    "        df['airport_fee'] = df['airport_fee'].fillna(0).astype(float, errors='ignore')\n",
    "        df['mta_tax'] = df['mta_tax'].astype(float, errors='ignore')\n",
    "        df['tolls_amount'] = df['tolls_amount'].astype(float, errors='ignore')\n",
    "        df['pickup_latitude'] = df['pickup_latitude'].astype(float, errors='ignore')\n",
    "        df['pickup_longitude'] = df['pickup_longitude'].astype(float, errors='ignore')\n",
    "        df['dropoff_latitude'] = df['dropoff_latitude'].astype(float, errors='ignore')\n",
    "        df['dropoff_longitude'] = df['dropoff_longitude'].astype(float, errors='ignore')\n",
    "        df['trip_distance'] = df['trip_distance'].astype(float, errors='ignore')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # calculate sample size and generate sampled_df\n",
    "        population_size = len(df)\n",
    "        sample_size = calculate_sample_size(population_size, confidence_level=0.95, margin_of_error=0.05)\n",
    "        sampled_df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "        # Append cleaned and sampled data to the list\n",
    "        all_cleaned_data.append(sampled_df)\n",
    "        print(f\"Finished processing file: {file_path}\")\n",
    "    \n",
    "    # Combine all cleaned DataFrames\n",
    "    combined_df = pd.concat(all_cleaned_data, ignore_index=True)\n",
    "    print(f\"Combined all cleaned data into a single DataFrame with {len(combined_df)} rows.\")\n",
    "\n",
    "    # Save the combined DataFrame to a Parquet file\n",
    "    combined_df.to_parquet(output_file, index=False)\n",
    "    print(f\"Saved combined data to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d140f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_input_directory = f\"{dataset_directory}/yellow_tripdata\"\n",
    "taxi_output_file = f\"{dataset_directory}/combined_taxi_data.parquet\"\n",
    "apply_cleaning_and_combine_taxi(taxi_input_directory, taxi_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb656e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data=pd.read_parquet(taxi_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c958e185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-27 16:50:19</td>\n",
       "      <td>2023-06-27 16:55:31</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.756687</td>\n",
       "      <td>-73.972356</td>\n",
       "      <td>40.758027</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-28 14:01:22</td>\n",
       "      <td>2023-06-28 14:16:21</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.706808</td>\n",
       "      <td>-74.007496</td>\n",
       "      <td>40.734575</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-09 20:04:55</td>\n",
       "      <td>2023-06-09 20:12:42</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.748427</td>\n",
       "      <td>-73.999917</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-04 01:03:00</td>\n",
       "      <td>2023-06-04 01:08:15</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.734575</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>40.723888</td>\n",
       "      <td>-74.001537</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-30 08:07:36</td>\n",
       "      <td>2023-06-30 08:13:14</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957011</td>\n",
       "      <td>40.790010</td>\n",
       "      <td>-73.945750</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21550</th>\n",
       "      <td>2023-03-01 22:21:47</td>\n",
       "      <td>2023-03-01 22:36:55</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6.27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.55</td>\n",
       "      <td>40.753512</td>\n",
       "      <td>-73.988786</td>\n",
       "      <td>40.729506</td>\n",
       "      <td>-73.949540</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21551</th>\n",
       "      <td>2023-03-01 15:57:02</td>\n",
       "      <td>2023-03-01 16:06:07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.818257</td>\n",
       "      <td>-73.940771</td>\n",
       "      <td>40.801169</td>\n",
       "      <td>-73.937345</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21552</th>\n",
       "      <td>2023-03-06 17:46:31</td>\n",
       "      <td>2023-03-06 17:53:27</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.732579</td>\n",
       "      <td>-73.994305</td>\n",
       "      <td>40.742278</td>\n",
       "      <td>-73.996971</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21553</th>\n",
       "      <td>2023-03-22 17:44:43</td>\n",
       "      <td>2023-03-22 17:55:28</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.987645</td>\n",
       "      <td>40.762252</td>\n",
       "      <td>-73.989844</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21554</th>\n",
       "      <td>2023-03-15 20:53:02</td>\n",
       "      <td>2023-03-15 20:59:44</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.766948</td>\n",
       "      <td>-73.959635</td>\n",
       "      <td>40.749913</td>\n",
       "      <td>-73.970442</td>\n",
       "      <td>1.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21555 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tpep_pickup_datetime tpep_dropoff_datetime  fare_amount  tip_amount  \\\n",
       "0      2023-06-27 16:50:19   2023-06-27 16:55:31          6.5        1.00   \n",
       "1      2023-06-28 14:01:22   2023-06-28 14:16:21         19.8        0.00   \n",
       "2      2023-06-09 20:04:55   2023-06-09 20:12:42          9.3        3.16   \n",
       "3      2023-06-04 01:03:00   2023-06-04 01:08:15          6.5        2.00   \n",
       "4      2023-06-30 08:07:36   2023-06-30 08:13:14          7.9        1.00   \n",
       "...                    ...                   ...          ...         ...   \n",
       "21550  2023-03-01 22:21:47   2023-03-01 22:36:55         19.8        6.27   \n",
       "21551  2023-03-01 15:57:02   2023-03-01 16:06:07         10.0        0.00   \n",
       "21552  2023-03-06 17:46:31   2023-03-06 17:53:27          8.6        0.00   \n",
       "21553  2023-03-22 17:44:43   2023-03-22 17:55:28         10.7        0.00   \n",
       "21554  2023-03-15 20:53:02   2023-03-15 20:59:44          9.3        2.85   \n",
       "\n",
       "       extra  improvement_surcharge  congestion_surcharge  airport_fee  \\\n",
       "0        2.5                    1.0                   2.5          0.0   \n",
       "1        0.0                    1.0                   2.5          0.0   \n",
       "2        2.5                    1.0                   2.5          0.0   \n",
       "3        3.5                    1.0                   2.5          0.0   \n",
       "4        2.5                    1.0                   2.5          0.0   \n",
       "...      ...                    ...                   ...          ...   \n",
       "21550    1.0                    1.0                   2.5          0.0   \n",
       "21551    0.0                    1.0                   0.0          0.0   \n",
       "21552    2.5                    1.0                   2.5          0.0   \n",
       "21553    5.0                    1.0                   2.5          0.0   \n",
       "21554    3.5                    1.0                   2.5          0.0   \n",
       "\n",
       "       mta_tax  tolls_amount  pickup_latitude  pickup_longitude  \\\n",
       "0          0.5          0.00        40.756687        -73.972356   \n",
       "1          0.5          0.00        40.706808        -74.007496   \n",
       "2          0.5          0.00        40.748427        -73.999917   \n",
       "3          0.5          0.00        40.734575        -74.002875   \n",
       "4          0.5          0.00        40.780436        -73.957011   \n",
       "...        ...           ...              ...               ...   \n",
       "21550      0.5          6.55        40.753512        -73.988786   \n",
       "21551      0.5          0.00        40.818257        -73.940771   \n",
       "21552      0.5          0.00        40.732579        -73.994305   \n",
       "21553      0.5          0.00        40.775965        -73.987645   \n",
       "21554      0.5          0.00        40.766948        -73.959635   \n",
       "\n",
       "       dropoff_latitude  dropoff_longitude  trip_distance  \n",
       "0             40.758027         -73.977698           0.70  \n",
       "1             40.734575         -74.002875           3.73  \n",
       "2             40.735035         -74.008984           1.06  \n",
       "3             40.723888         -74.001537           0.70  \n",
       "4             40.790010         -73.945750           0.80  \n",
       "...                 ...                ...            ...  \n",
       "21550         40.729506         -73.949540           3.94  \n",
       "21551         40.801169         -73.937345           0.88  \n",
       "21552         40.742278         -73.996971           1.07  \n",
       "21553         40.762252         -73.989844           1.10  \n",
       "21554         40.749913         -73.970442           1.40  \n",
       "\n",
       "[21555 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b7bbec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-27 16:50:19</td>\n",
       "      <td>2023-06-27 16:55:31</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.756687</td>\n",
       "      <td>-73.972356</td>\n",
       "      <td>40.758027</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-28 14:01:22</td>\n",
       "      <td>2023-06-28 14:16:21</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.706808</td>\n",
       "      <td>-74.007496</td>\n",
       "      <td>40.734575</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-09 20:04:55</td>\n",
       "      <td>2023-06-09 20:12:42</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.748427</td>\n",
       "      <td>-73.999917</td>\n",
       "      <td>40.735035</td>\n",
       "      <td>-74.008984</td>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-04 01:03:00</td>\n",
       "      <td>2023-06-04 01:08:15</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.734575</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>40.723888</td>\n",
       "      <td>-74.001537</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-30 08:07:36</td>\n",
       "      <td>2023-06-30 08:13:14</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957011</td>\n",
       "      <td>40.790010</td>\n",
       "      <td>-73.945750</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tpep_pickup_datetime tpep_dropoff_datetime  fare_amount  tip_amount  extra  \\\n",
       "0  2023-06-27 16:50:19   2023-06-27 16:55:31          6.5        1.00    2.5   \n",
       "1  2023-06-28 14:01:22   2023-06-28 14:16:21         19.8        0.00    0.0   \n",
       "2  2023-06-09 20:04:55   2023-06-09 20:12:42          9.3        3.16    2.5   \n",
       "3  2023-06-04 01:03:00   2023-06-04 01:08:15          6.5        2.00    3.5   \n",
       "4  2023-06-30 08:07:36   2023-06-30 08:13:14          7.9        1.00    2.5   \n",
       "\n",
       "   improvement_surcharge  congestion_surcharge  airport_fee  mta_tax  \\\n",
       "0                    1.0                   2.5          0.0      0.5   \n",
       "1                    1.0                   2.5          0.0      0.5   \n",
       "2                    1.0                   2.5          0.0      0.5   \n",
       "3                    1.0                   2.5          0.0      0.5   \n",
       "4                    1.0                   2.5          0.0      0.5   \n",
       "\n",
       "   tolls_amount  pickup_latitude  pickup_longitude  dropoff_latitude  \\\n",
       "0           0.0        40.756687        -73.972356         40.758027   \n",
       "1           0.0        40.706808        -74.007496         40.734575   \n",
       "2           0.0        40.748427        -73.999917         40.735035   \n",
       "3           0.0        40.734575        -74.002875         40.723888   \n",
       "4           0.0        40.780436        -73.957011         40.790010   \n",
       "\n",
       "   dropoff_longitude  trip_distance  \n",
       "0         -73.977698           0.70  \n",
       "1         -74.002875           3.73  \n",
       "2         -74.008984           1.06  \n",
       "3         -74.001537           0.70  \n",
       "4         -73.945750           0.80  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c61f15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21555 entries, 0 to 21554\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   tpep_pickup_datetime   21555 non-null  datetime64[ns]\n",
      " 1   tpep_dropoff_datetime  21555 non-null  datetime64[ns]\n",
      " 2   fare_amount            21555 non-null  float64       \n",
      " 3   tip_amount             21555 non-null  float64       \n",
      " 4   extra                  21555 non-null  float64       \n",
      " 5   improvement_surcharge  21555 non-null  float64       \n",
      " 6   congestion_surcharge   21555 non-null  float64       \n",
      " 7   airport_fee            21555 non-null  float64       \n",
      " 8   mta_tax                21555 non-null  float64       \n",
      " 9   tolls_amount           21555 non-null  float64       \n",
      " 10  pickup_latitude        21555 non-null  float64       \n",
      " 11  pickup_longitude       21555 non-null  float64       \n",
      " 12  dropoff_latitude       21555 non-null  float64       \n",
      " 13  dropoff_longitude      21555 non-null  float64       \n",
      " 14  trip_distance          21555 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(13)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b1c6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21555</td>\n",
       "      <td>21555</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "      <td>21555.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-02 02:22:55.033170688</td>\n",
       "      <td>2022-05-02 02:40:03.177824256</td>\n",
       "      <td>15.498320</td>\n",
       "      <td>2.817350</td>\n",
       "      <td>1.273732</td>\n",
       "      <td>0.553250</td>\n",
       "      <td>2.326374</td>\n",
       "      <td>0.090478</td>\n",
       "      <td>0.498056</td>\n",
       "      <td>0.469210</td>\n",
       "      <td>40.753237</td>\n",
       "      <td>-73.967072</td>\n",
       "      <td>40.755621</td>\n",
       "      <td>-73.971460</td>\n",
       "      <td>3.319831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 03:06:55</td>\n",
       "      <td>2020-01-01 03:13:30</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>40.571769</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-01 17:26:52</td>\n",
       "      <td>2021-03-01 17:35:34</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.740438</td>\n",
       "      <td>-73.989844</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989844</td>\n",
       "      <td>1.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-01 11:01:50</td>\n",
       "      <td>2022-05-01 11:21:35</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.758027</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758027</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>1.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-01 00:33:29.500000</td>\n",
       "      <td>2023-07-01 00:48:51.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.560000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>40.774375</td>\n",
       "      <td>-73.959635</td>\n",
       "      <td>3.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 21:58:30</td>\n",
       "      <td>2024-08-31 22:21:51</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.739473</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.735555</td>\n",
       "      <td>57.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.730091</td>\n",
       "      <td>3.239298</td>\n",
       "      <td>1.530403</td>\n",
       "      <td>0.336887</td>\n",
       "      <td>0.635560</td>\n",
       "      <td>0.361685</td>\n",
       "      <td>0.031472</td>\n",
       "      <td>1.891135</td>\n",
       "      <td>0.031175</td>\n",
       "      <td>0.045508</td>\n",
       "      <td>0.032247</td>\n",
       "      <td>0.035536</td>\n",
       "      <td>4.106375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tpep_pickup_datetime          tpep_dropoff_datetime  \\\n",
       "count                          21555                          21555   \n",
       "mean   2022-05-02 02:22:55.033170688  2022-05-02 02:40:03.177824256   \n",
       "min              2020-01-01 03:06:55            2020-01-01 03:13:30   \n",
       "25%              2021-03-01 17:26:52            2021-03-01 17:35:34   \n",
       "50%              2022-05-01 11:01:50            2022-05-01 11:21:35   \n",
       "75%       2023-07-01 00:33:29.500000     2023-07-01 00:48:51.500000   \n",
       "max              2024-08-31 21:58:30            2024-08-31 22:21:51   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "        fare_amount    tip_amount         extra  improvement_surcharge  \\\n",
       "count  21555.000000  21555.000000  21555.000000           21555.000000   \n",
       "mean      15.498320      2.817350      1.273732               0.553250   \n",
       "min        0.010000      0.000000      0.000000               0.000000   \n",
       "25%        7.500000      0.180000      0.000000               0.300000   \n",
       "50%       11.000000      2.260000      1.000000               0.300000   \n",
       "75%       17.000000      3.560000      2.500000               1.000000   \n",
       "max      159.800000     99.990000     11.750000               1.000000   \n",
       "std       13.730091      3.239298      1.530403               0.336887   \n",
       "\n",
       "       congestion_surcharge   airport_fee       mta_tax  tolls_amount  \\\n",
       "count          21555.000000  21555.000000  21555.000000  21555.000000   \n",
       "mean               2.326374      0.090478      0.498056      0.469210   \n",
       "min                0.000000      0.000000      0.000000      0.000000   \n",
       "25%                2.500000      0.000000      0.500000      0.000000   \n",
       "50%                2.500000      0.000000      0.500000      0.000000   \n",
       "75%                2.500000      0.000000      0.500000      0.000000   \n",
       "max                2.500000      1.750000      0.800000     40.000000   \n",
       "std                0.635560      0.361685      0.031472      1.891135   \n",
       "\n",
       "       pickup_latitude  pickup_longitude  dropoff_latitude  dropoff_longitude  \\\n",
       "count     21555.000000      21555.000000      21555.000000       21555.000000   \n",
       "mean         40.753237        -73.967072         40.755621         -73.971460   \n",
       "min          40.576961        -74.174000         40.571769         -74.174000   \n",
       "25%          40.740438        -73.989844         40.740337         -73.989844   \n",
       "50%          40.758027        -73.977698         40.758027         -73.977698   \n",
       "75%          40.773633        -73.965146         40.774375         -73.959635   \n",
       "max          40.897932        -73.739473         40.899529         -73.735555   \n",
       "std           0.031175          0.045508          0.032247           0.035536   \n",
       "\n",
       "       trip_distance  \n",
       "count   21555.000000  \n",
       "mean        3.319831  \n",
       "min         0.010000  \n",
       "25%         1.160000  \n",
       "50%         1.870000  \n",
       "75%         3.320000  \n",
       "max        57.700000  \n",
       "std         4.106375  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbf225",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f49e0785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cleaning_and_combine_uber(input_directory, intermediate_directory, output_file):\n",
    "    \"\"\"\n",
    "    Process each Parquet file individually and save cleaned data as intermediate files.\n",
    "    Then combine all intermediate files into a single large Parquet file.\n",
    "\n",
    "    Args:\n",
    "        input_directory (str): Path to the directory containing the Parquet files.\n",
    "        intermediate_directory (str): Path to save intermediate cleaned files.\n",
    "        output_file (str): Path to save the final combined Parquet file.\n",
    "        confidence_level (float): Confidence level for sample size calculation.\n",
    "        margin_of_error (float): Margin of error for sample size calculation.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Ensure the intermediate directory exists\n",
    "    os.makedirs(intermediate_directory, exist_ok=True)\n",
    "\n",
    "    # Get all Parquet files in the directory\n",
    "    parquet_files = glob.glob(f\"{input_directory}/*.parquet\")\n",
    "    \n",
    "    for file_path in parquet_files:\n",
    "        try:\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            \n",
    "            # Load the file\n",
    "            df = pd.read_parquet(file_path)\n",
    "            \n",
    "            # Filter Uber rides\n",
    "            df = df[df['hvfhs_license_num'] == 'HV0003']\n",
    "\n",
    "            # Load taxi zones for mapping\n",
    "            taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "            taxi_zones = taxi_zones[['LocationID', 'longitude', 'latitude', 'zone', 'borough']]\n",
    "            lat_map = dict(zip(taxi_zones['LocationID'], taxi_zones['latitude']))\n",
    "            lon_map = dict(zip(taxi_zones['LocationID'], taxi_zones['longitude']))\n",
    "\n",
    "            # Map latitude and longitude\n",
    "            df['pickup_latitude'] = df['PULocationID'].map(lat_map)\n",
    "            df['pickup_longitude'] = df['PULocationID'].map(lon_map)\n",
    "            df['dropoff_latitude'] = df['DOLocationID'].map(lat_map)\n",
    "            df['dropoff_longitude'] = df['DOLocationID'].map(lon_map)\n",
    "\n",
    "            # Drop rows with missing latitude and longitude\n",
    "            df = df.dropna(subset=['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n",
    "\n",
    "            # Filter invalid data points\n",
    "            df = df[(df['trip_miles'] > 0) & (df['trip_time'] > 0) &\n",
    "                    (df['base_passenger_fare'] >= 0) & (df['tolls'] >= 0) &\n",
    "                    (df['bcf'] >= 0) & (df['sales_tax'] >= 0) & (df['tips'] >= 0) &\n",
    "                    (df['driver_pay'] >= 0) & (df['congestion_surcharge'] >= 0)]\n",
    "\n",
    "            # Remove trips that start and/or end outside of the NEW_YORK_BOX\n",
    "            NEW_YORK_BOX_COORDS = [(40.560445, -74.242330), (40.908524, -73.717047)]\n",
    "            df = df[(df['pickup_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & \n",
    "                    (df['pickup_latitude'] <= NEW_YORK_BOX_COORDS[1][0]) & \n",
    "                    (df['pickup_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & \n",
    "                    (df['pickup_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "            df = df[(df['dropoff_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & \n",
    "                    (df['dropoff_latitude'] <= NEW_YORK_BOX_COORDS[1][0]) & \n",
    "                    (df['dropoff_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & \n",
    "                    (df['dropoff_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "\n",
    "             # Normalize column names\n",
    "            df.columns = [col.lower().strip().replace(' ', '_') for col in df.columns]\n",
    "\n",
    "            # Drop unnecessary columns\n",
    "            df = df[['pickup_datetime',\n",
    "                     'dropoff_datetime',\n",
    "                     'trip_miles',\n",
    "                     'trip_time',\n",
    "                     'base_passenger_fare',\n",
    "                     'tolls',\n",
    "                     'bcf',\n",
    "                     'sales_tax',\n",
    "                     'congestion_surcharge',\n",
    "                     'airport_fee',\n",
    "                     'tips',\n",
    "                     'pickup_latitude',\n",
    "                     'pickup_longitude',\n",
    "                     'dropoff_latitude',\n",
    "                     'dropoff_longitude']]\n",
    "            \n",
    "            # convert datatype after filtering\n",
    "            df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')\n",
    "            df['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], errors='coerce')\n",
    "            df['trip_miles'] = df['trip_miles'].astype(float)\n",
    "            df['trip_time'] = df['trip_time'].astype(float)\n",
    "            df['base_passenger_fare'] = df['base_passenger_fare'].astype(float)\n",
    "            df['tolls'] = df['tolls'].astype(float)\n",
    "            df['bcf'] = df['bcf'].astype(float)\n",
    "            df['sales_tax'] = df['sales_tax'].astype(float)\n",
    "            df['congestion_surcharge'] = df['congestion_surcharge'].astype(float)\n",
    "            df['airport_fee'] = df['airport_fee'].fillna(0).astype(float)\n",
    "            df['tips'] = df['tips'].astype(float)\n",
    "            df['pickup_latitude'] = df['pickup_latitude'].astype(float)\n",
    "            df['pickup_longitude'] = df['pickup_longitude'].astype(float)\n",
    "            df['dropoff_latitude'] = df['dropoff_latitude'].astype(float)\n",
    "            df['dropoff_longitude'] = df['dropoff_longitude'].astype(float)\n",
    "\n",
    "            # calculate sample size and generate sampled_df\n",
    "            population_size = len(df)\n",
    "            sample_size = calculate_sample_size(population_size, confidence_level=0.95, margin_of_error=0.05)\n",
    "            sampled_df = df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "            # Save cleaned file as intermediate Parquet\n",
    "            intermediate_file = os.path.join(intermediate_directory, os.path.basename(file_path))\n",
    "            sampled_df.to_parquet(intermediate_file, index=False)\n",
    "            print(f\"Saved intermediate cleaned data to: {intermediate_file}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Combine all intermediate files into the final Parquet file\n",
    "    intermediate_files = glob.glob(f\"{intermediate_directory}/*.parquet\")\n",
    "    all_dataframes = []\n",
    "    \n",
    "    for intermediate_file in intermediate_files:\n",
    "        try:\n",
    "            print(f\"Loading intermediate file: {intermediate_file}\")\n",
    "            df = pd.read_parquet(intermediate_file)\n",
    "            all_dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading intermediate file {intermediate_file}: {e}\")\n",
    "\n",
    "\n",
    "    # Concatenate all cleaned intermediate files and save as one large file\n",
    "    if all_dataframes:\n",
    "        combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "        combined_df.to_parquet(output_file, index=False)\n",
    "        print(f\"Saved combined data to: {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid data to combine.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12c690d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_input_directory = f\"{dataset_directory}/fhvhv_tripdata\"\n",
    "uber_intermediate_directory = f\"{dataset_directory}/intermediate_cleaned_uber\"\n",
    "uber_output_file = f\"{dataset_directory}/combined_uber_data.parquet\"\n",
    "\n",
    "apply_cleaning_and_combine_uber(uber_input_directory, uber_intermediate_directory, uber_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e307940",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = pd.read_parquet(uber_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcbe6c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-10 07:37:01</td>\n",
       "      <td>2021-03-10 07:48:59</td>\n",
       "      <td>2.15</td>\n",
       "      <td>718.0</td>\n",
       "      <td>10.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.688721</td>\n",
       "      <td>-73.855767</td>\n",
       "      <td>40.694542</td>\n",
       "      <td>-73.830924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-18 08:21:36</td>\n",
       "      <td>2021-03-18 08:33:29</td>\n",
       "      <td>1.34</td>\n",
       "      <td>713.0</td>\n",
       "      <td>9.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.736823</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>40.753512</td>\n",
       "      <td>-73.988786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-17 07:48:16</td>\n",
       "      <td>2021-03-17 08:02:38</td>\n",
       "      <td>4.56</td>\n",
       "      <td>862.0</td>\n",
       "      <td>18.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.742671</td>\n",
       "      <td>-73.754622</td>\n",
       "      <td>40.783332</td>\n",
       "      <td>-73.785972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-14 10:52:12</td>\n",
       "      <td>2021-03-14 11:03:28</td>\n",
       "      <td>2.69</td>\n",
       "      <td>676.0</td>\n",
       "      <td>15.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.876512</td>\n",
       "      <td>-73.895620</td>\n",
       "      <td>40.882403</td>\n",
       "      <td>-73.910665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-28 11:50:29</td>\n",
       "      <td>2021-03-28 11:57:33</td>\n",
       "      <td>0.68</td>\n",
       "      <td>424.0</td>\n",
       "      <td>14.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.717772</td>\n",
       "      <td>-74.007880</td>\n",
       "      <td>40.717772</td>\n",
       "      <td>-74.007880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  trip_miles  trip_time  \\\n",
       "0 2021-03-10 07:37:01 2021-03-10 07:48:59        2.15      718.0   \n",
       "1 2021-03-18 08:21:36 2021-03-18 08:33:29        1.34      713.0   \n",
       "2 2021-03-17 07:48:16 2021-03-17 08:02:38        4.56      862.0   \n",
       "3 2021-03-14 10:52:12 2021-03-14 11:03:28        2.69      676.0   \n",
       "4 2021-03-28 11:50:29 2021-03-28 11:57:33        0.68      424.0   \n",
       "\n",
       "   base_passenger_fare  tolls   bcf  sales_tax  congestion_surcharge  \\\n",
       "0                10.71    0.0  0.32       0.95                  0.00   \n",
       "1                 9.79    0.0  0.00       0.00                  2.75   \n",
       "2                18.28    0.0  0.55       1.62                  0.00   \n",
       "3                15.16    0.0  0.45       1.35                  0.00   \n",
       "4                14.15    0.0  0.42       1.26                  2.75   \n",
       "\n",
       "   airport_fee  tips  pickup_latitude  pickup_longitude  dropoff_latitude  \\\n",
       "0          0.0   0.0        40.688721        -73.855767         40.694542   \n",
       "1          0.0   2.0        40.736823        -73.984052         40.753512   \n",
       "2          0.0   0.0        40.742671        -73.754622         40.783332   \n",
       "3          0.0   0.0        40.876512        -73.895620         40.882403   \n",
       "4          0.0   0.0        40.717772        -74.007880         40.717772   \n",
       "\n",
       "   dropoff_longitude  \n",
       "0         -73.830924  \n",
       "1         -73.988786  \n",
       "2         -73.785972  \n",
       "3         -73.910665  \n",
       "4         -74.007880  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fecf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21560 entries, 0 to 21559\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   pickup_datetime       21560 non-null  datetime64[ns]\n",
      " 1   dropoff_datetime      21560 non-null  datetime64[ns]\n",
      " 2   trip_miles            21560 non-null  float64       \n",
      " 3   trip_time             21560 non-null  float64       \n",
      " 4   base_passenger_fare   21560 non-null  float64       \n",
      " 5   tolls                 21560 non-null  float64       \n",
      " 6   bcf                   21560 non-null  float64       \n",
      " 7   sales_tax             21560 non-null  float64       \n",
      " 8   congestion_surcharge  21560 non-null  float64       \n",
      " 9   airport_fee           21560 non-null  float64       \n",
      " 10  tips                  21560 non-null  float64       \n",
      " 11  pickup_latitude       21560 non-null  float64       \n",
      " 12  pickup_longitude      21560 non-null  float64       \n",
      " 13  dropoff_latitude      21560 non-null  float64       \n",
      " 14  dropoff_longitude     21560 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(13)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a804b458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>base_passenger_fare</th>\n",
       "      <th>tolls</th>\n",
       "      <th>bcf</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21560</td>\n",
       "      <td>21560</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "      <td>21560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-02 01:18:57.684322816</td>\n",
       "      <td>2022-05-02 01:36:50.816744192</td>\n",
       "      <td>4.379178</td>\n",
       "      <td>1073.391141</td>\n",
       "      <td>21.124263</td>\n",
       "      <td>0.628066</td>\n",
       "      <td>0.616259</td>\n",
       "      <td>1.883285</td>\n",
       "      <td>1.048782</td>\n",
       "      <td>0.133291</td>\n",
       "      <td>0.792580</td>\n",
       "      <td>40.737920</td>\n",
       "      <td>-73.934695</td>\n",
       "      <td>40.737407</td>\n",
       "      <td>-73.934451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:21:55</td>\n",
       "      <td>2020-01-01 00:40:45</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.186419</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-01 02:25:26.750000128</td>\n",
       "      <td>2021-03-01 02:43:57.500000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>10.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.691201</td>\n",
       "      <td>-73.984196</td>\n",
       "      <td>40.691201</td>\n",
       "      <td>-73.984052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-30 22:29:27</td>\n",
       "      <td>2022-04-30 22:48:34.500000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>16.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.737698</td>\n",
       "      <td>-73.948789</td>\n",
       "      <td>40.737698</td>\n",
       "      <td>-73.947442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-01 00:01:51.249999872</td>\n",
       "      <td>2023-07-01 00:14:48.500000</td>\n",
       "      <td>5.570000</td>\n",
       "      <td>1378.000000</td>\n",
       "      <td>26.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.774375</td>\n",
       "      <td>-73.899735</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.898956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 23:07:13</td>\n",
       "      <td>2024-08-31 23:19:20</td>\n",
       "      <td>42.780000</td>\n",
       "      <td>8862.000000</td>\n",
       "      <td>213.740000</td>\n",
       "      <td>46.210000</td>\n",
       "      <td>6.140000</td>\n",
       "      <td>19.810000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726656</td>\n",
       "      <td>40.899529</td>\n",
       "      <td>-73.726656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.285147</td>\n",
       "      <td>740.388956</td>\n",
       "      <td>15.781332</td>\n",
       "      <td>2.525454</td>\n",
       "      <td>0.500672</td>\n",
       "      <td>1.435071</td>\n",
       "      <td>1.330371</td>\n",
       "      <td>0.566746</td>\n",
       "      <td>2.399464</td>\n",
       "      <td>0.068442</td>\n",
       "      <td>0.064763</td>\n",
       "      <td>0.068879</td>\n",
       "      <td>0.067801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pickup_datetime               dropoff_datetime  \\\n",
       "count                          21560                          21560   \n",
       "mean   2022-05-02 01:18:57.684322816  2022-05-02 01:36:50.816744192   \n",
       "min              2020-01-01 00:21:55            2020-01-01 00:40:45   \n",
       "25%    2021-03-01 02:25:26.750000128     2021-03-01 02:43:57.500000   \n",
       "50%              2022-04-30 22:29:27     2022-04-30 22:48:34.500000   \n",
       "75%    2023-07-01 00:01:51.249999872     2023-07-01 00:14:48.500000   \n",
       "max              2024-08-31 23:07:13            2024-08-31 23:19:20   \n",
       "std                              NaN                            NaN   \n",
       "\n",
       "         trip_miles     trip_time  base_passenger_fare         tolls  \\\n",
       "count  21560.000000  21560.000000         21560.000000  21560.000000   \n",
       "mean       4.379178   1073.391141            21.124263      0.628066   \n",
       "min        0.040000     68.000000             0.000000      0.000000   \n",
       "25%        1.550000    560.000000            10.560000      0.000000   \n",
       "50%        2.820000    880.000000            16.590000      0.000000   \n",
       "75%        5.570000   1378.000000            26.190000      0.000000   \n",
       "max       42.780000   8862.000000           213.740000     46.210000   \n",
       "std        4.285147    740.388956            15.781332      2.525454   \n",
       "\n",
       "                bcf     sales_tax  congestion_surcharge   airport_fee  \\\n",
       "count  21560.000000  21560.000000          21560.000000  21560.000000   \n",
       "mean       0.616259      1.883285              1.048782      0.133291   \n",
       "min        0.000000      0.000000              0.000000      0.000000   \n",
       "25%        0.290000      0.920000              0.000000      0.000000   \n",
       "50%        0.470000      1.460000              0.000000      0.000000   \n",
       "75%        0.760000      2.360000              2.750000      0.000000   \n",
       "max        6.140000     19.810000              2.750000      5.000000   \n",
       "std        0.500672      1.435071              1.330371      0.566746   \n",
       "\n",
       "               tips  pickup_latitude  pickup_longitude  dropoff_latitude  \\\n",
       "count  21560.000000     21560.000000      21560.000000      21560.000000   \n",
       "mean       0.792580        40.737920        -73.934695         40.737407   \n",
       "min        0.000000        40.561994        -74.186419         40.561994   \n",
       "25%        0.000000        40.691201        -73.984196         40.691201   \n",
       "50%        0.000000        40.737698        -73.948789         40.737698   \n",
       "75%        0.000000        40.774375        -73.899735         40.775932   \n",
       "max       50.000000        40.899529        -73.726656         40.899529   \n",
       "std        2.399464         0.068442          0.064763          0.068879   \n",
       "\n",
       "       dropoff_longitude  \n",
       "count       21560.000000  \n",
       "mean          -73.934451  \n",
       "min           -74.174000  \n",
       "25%           -73.984052  \n",
       "50%           -73.947442  \n",
       "75%           -73.898956  \n",
       "max           -73.726656  \n",
       "std             0.067801  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9588cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
